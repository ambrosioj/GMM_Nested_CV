{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 20835,
     "status": "ok",
     "timestamp": 1628702163805,
     "user": {
      "displayName": "Andr√© Eugenio Lazzaretti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gho24SuaAM-AZg1XCClGW2K7D7ScpS1acVwfWes3g=s64",
      "userId": "07958666682882432874"
     },
     "user_tz": 180
    },
    "id": "ZzJD_xHMrruy"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score\n",
    "import numpy as np\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 10\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000]},\n",
    "          {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "# We will use a Support Vector Classifier with \"rbf\" kernel\n",
    "svm = SVC()\n",
    "\n",
    "# Arrays to store scores\n",
    "train_scores_accuracy_avg = np.zeros(NUM_TRIALS)\n",
    "train_scores_accuracy_std = np.zeros(NUM_TRIALS)\n",
    "train_scores_fmacro_avg = np.zeros(NUM_TRIALS)\n",
    "train_scores_fmacro_std = np.zeros(NUM_TRIALS)\n",
    "train_scores_fmicro_avg = np.zeros(NUM_TRIALS)\n",
    "train_scores_fmicro_std = np.zeros(NUM_TRIALS)\n",
    "test_scores_accuracy_avg = np.zeros(NUM_TRIALS)\n",
    "test_scores_accuracy_std = np.zeros(NUM_TRIALS)\n",
    "test_scores_fmacro_avg = np.zeros(NUM_TRIALS)\n",
    "test_scores_fmacro_std = np.zeros(NUM_TRIALS)\n",
    "test_scores_fmicro_avg = np.zeros(NUM_TRIALS)\n",
    "test_scores_fmicro_std = np.zeros(NUM_TRIALS)\n",
    "best_params = {\"C\":[],\"kernel\":[],\"gamma\":[]}\n",
    "\n",
    "# Loop for each trial\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "    inner_cv = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv)\n",
    "    clf.fit(X_iris, y_iris)\n",
    "    best_params[\"C\"].append(clf.best_params_[\"C\"])\n",
    "    best_params[\"kernel\"].append(clf.best_params_[\"kernel\"])\n",
    "    if \"gamma\" in clf.best_params_:\n",
    "        best_params[\"gamma\"].append(clf.best_params_[\"gamma\"])\n",
    "    else:\n",
    "        best_params[\"gamma\"].append(0)\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    scoring = {'acc': 'accuracy',\n",
    "               'fmacro': 'f1_macro',\n",
    "               'fmicro': 'f1_micro'}\n",
    "\n",
    "    nested_score = cross_validate(clf, X=X_iris, y=y_iris, scoring=scoring, cv=outer_cv, return_train_score=True)\n",
    "    train_scores_accuracy_avg[i] = nested_score[\"train_acc\"].mean()\n",
    "    train_scores_accuracy_std[i] = nested_score[\"train_acc\"].std()\n",
    "    train_scores_fmacro_avg[i] = nested_score[\"train_fmacro\"].mean()\n",
    "    train_scores_fmacro_std[i] = nested_score[\"train_fmacro\"].std()\n",
    "    train_scores_fmicro_avg[i] = nested_score[\"train_fmicro\"].mean()\n",
    "    train_scores_fmicro_std[i] = nested_score[\"train_fmicro\"].std()\n",
    "    test_scores_accuracy_avg[i] = nested_score[\"test_acc\"].mean()\n",
    "    test_scores_accuracy_std[i] = nested_score[\"test_acc\"].std()\n",
    "    test_scores_fmacro_avg[i] = nested_score[\"test_fmacro\"].mean()\n",
    "    test_scores_fmacro_std[i] = nested_score[\"test_fmacro\"].std()\n",
    "    test_scores_fmicro_avg[i] = nested_score[\"test_fmicro\"].mean()\n",
    "    test_scores_fmicro_std[i] = nested_score[\"test_fmicro\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "beX4UCPGru8i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'kernel': ['rbf'], 'gamma': [0.001, 0.0001], 'C': [1, 10, 100, 1000]},\n",
       " {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fit_time', 'score_time', 'test_acc', 'train_acc', 'test_fmacro', 'train_fmacro', 'test_fmicro', 'train_fmicro'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_score.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': [1, 1000, 1000, 1000, 1, 1, 1000, 1000, 10, 100],\n",
       " 'kernel': ['linear',\n",
       "  'rbf',\n",
       "  'linear',\n",
       "  'linear',\n",
       "  'linear',\n",
       "  'linear',\n",
       "  'rbf',\n",
       "  'rbf',\n",
       "  'linear',\n",
       "  'rbf'],\n",
       " 'gamma': [0, 0.001, 0, 0, 0, 0, 0.001, 0.001, 0, 0.001]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.93333333, 1.        ,\n",
       "       0.93333333, 0.93333333, 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_score[\"test_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97333333, 0.95333333, 0.96      , 0.97333333, 0.98666667,\n",
       "       0.98      , 0.96666667, 0.96      , 0.97333333, 0.98      ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_accuracy_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_scores_accuracy_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "nested_cross_validation_iris.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
